#!/usr/bin/env python
# Copyright (C) Duncan Macleod (2016)
#
# This file is part of LIGO-Omicron.
#
# LIGO-Omicron is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# LIGO-Omicron is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with LIGO-Omicron.  If not, see <http://www.gnu.org/licenses/>.

"""Process LIGO data using the Omicron event trigger generator (ETG)

This utility can be used to process one or more channels or LIGO data using
Omicron with minimal manual labour in determining segments, finding data,
and configuring HTCondor.

The input to this should be an INI-format configuration file that lists the
processing parameters and channels that pass to Omicron, something like:

```ini
[GW]
q-range = 3.3166 150
frequency-range = 4.0 8192.0
frametype = H1_HOFT_C00
state-flag = H1:DMT-CALIBRATED:1
sample-frequency = 16384
chunk-duration = 124
segment-duration = 64
overlap-duration = 4
mismatch-max = 0.2
snr-threshold = 5
channels = H1:GDS-CALIB_STRAIN
```

The above 'GW' group name should then be passed to `omicron-process` along
with any customisations available from the command line, e.g.

```
omicron-process GW --config-file ./config.ini
```

By default `omicron-process` will look at the most recent data available
('online' mode), to run in 'offline' mode, pass the `--gps` argument

```
omicron-process GW --config-file ./config.ini --gps <gpsstart> <gpsstop>
```

The output of `omicron-process` is a Directed Acyclic Graph (DAG) that is
*automatically* submitted to condor for processing.

"""

from __future__ import print_function

import argparse
import os
import sys
import shutil
import re
from time import sleep
from glob import glob
from getpass import getuser
from tempfile import (gettempdir, mkdtemp)

# python 3
try:
    import configparser
# python 2
except ImportError:
    import ConfigParser as configparser

import htcondor

from glue import pipeline
from glue.lal import (Cache, CacheEntry)

from omicron import (const, segments, log, data, parameters, utils, condor, io,
                     __version__)

__author__ = 'Duncan Macleod <duncan.macleod@ligo.org>'

logger = log.Logger('omicron-process')


# -- tempfile utilities

def clean_exit(exitcode, tempfiles=[]):
    clean_tempfiles(tempfiles)
    sys.exit(exitcode)


def clean_tempfiles(tempfiles):
    for f in tempfiles:
        if os.path.isdir(f):
            shutil.rmtree(f)
            logger.debug('Deleted directory %r' % f)
        else:
            os.remove(f)
            logger.debug('Deleted file %r' % f)


# -- parse command line

epilog = """This source code for this project is available here:

https://git.ligo.org/detchar/ligo-omicron/

All issues regarding this software should be raised using GitLab, bug reports and feature requests are encouraged.
"""

parser = argparse.ArgumentParser(
    description=__doc__,
    formatter_class=argparse.RawDescriptionHelpFormatter,
    epilog=epilog)
parser._positionals.title = 'Positional arguments'
parser._optionals.title = 'Optional arguments'

parser.add_argument('-V', '--version', action='version', version=__version__)
parser.add_argument('group', help='name of configuration group to process')
parser.add_argument('-t', '--gps', nargs=2, type=int,
                    metavar='GPSTIME',
                    help='GPS times for offline processing')
parser.add_argument('-f', '--config-file', default=const.OMICRON_CHANNELS_FILE,
                    help='path to configuration file, default: %(default)s')
parser.add_argument('-i', '--ifo', default=const.IFO,
                    help='IFO prefix to process, default: %(default)s')
parser.add_argument('-v', '--verbose', action='count', default=2,
                    help='print verbose output, give more times for more '
                         'verbose output')

outg = parser.add_argument_group('Output options')
outg.add_argument('-o', '--output-dir', default=os.curdir,
                  help='path to output directory, default: %(default)s')
outg.add_argument('-a', '--archive', action='store_true', default=False,
                  help='archive created files under %s, default: %%(default)s'
                       % const.OMICRON_ARCHIVE)
outg.add_argument('-g', '--file-tag', default='',
                  help='additional file tag to be appended to final '
                       'file descriptions')

procg = parser.add_argument_group('Processing options')
procg.add_argument('-C', '--max-chunks-per-job', type=int, default=4,
                   help='maximum number of chunks to process in a single '
                        'condor job, default: %(default)s')
procg.add_argument('-N', '--max-channels-per-job', type=int, default=10,
                   help='maximum number of channels to process in a single '
                        'condor job, default: %(default)s')
procg.add_argument('-x', '--exclude-channel', action='append', default=[],
                   help='exclude channel from the analysis (can be given '
                        'multiple times')

condorg = parser.add_argument_group('Condor options')
mode = condorg.add_mutually_exclusive_group()
mode.add_argument('--reattach', action='store_true', default=False,
                  help='if DAG already running, try and reattach to it '
                       'and follow it\'s progress, this is only designed '
                       'for online running')
mode.add_argument('--rescue', action='store_true', default=False,
                  help='rescue a failed DAG instead of creating a new one, '
                       'default: %(default)s')
mode.add_argument('--no-submit', action='store_true', default=False,
                  help='do not submit the DAG to condor, '
                       'default: %(default)s')
condorg.add_argument('--universe', default='vanilla',
                     choices=['vanilla', 'local'],
                     help='condor universe, default: %(default)s')
condorg.add_argument('--executable', default=utils.which('omicron.exe'),
                     help='omicron executable, default: %(default)s')
condorg.add_argument('--condor-retry', type=int, default=2,
                     help='number of times to retry each job if failed, '
                          'default: %(default)s')
condorg.add_argument('--condor-accounting-group',
                     default='ligo.dev.o1.detchar.transient.omicron',
                     help='accounting_group for condor submission on the LIGO '
                          'Data Grid, default: %(default)s')
condorg.add_argument('--condor-accounting-group-user', default=getuser(),
                     help='accounting_group_user for condor submission on the '
                          'LIGO Data Grid, default: %(default)s')
condorg.add_argument('--submit-rescue-dag', type=int, default=0,
                     help='number of times to automatically submit the '
                          'rescue DAG, default: %(default)s')
condorg.add_argument('-c', '--condor-command', action='append', type=str,
                     default=[], metavar="\"key=value\"",
                     help="Extra condor submit commands to add to "
                          "gw_summary submit file. Can be given "
                          "multiple times")
condorg.add_argument('-d', '--dagman-option', action='append', type=str,
                     default=['force'], metavar="\"opt | opt=value\"",
                     help="Extra options to pass to condor_submit_dag as "
                          "\"-{opt} [{value}]\". "
                          "Can be given multiple times, default: %(default)s")

datag = parser.add_argument_group('Data options')
datag.add_argument('--use-dev-shm', action='store_true', default=False,
                   help='use low-latency frame buffer in /dev/shm, '
                        'default: %(default)s')

pipeg = parser.add_argument_group('Pipeline options')
pipeg.add_argument('--skip-omicron', action='store_true', default=False,
                   help='skip running omicron, default: %(default)s')
pipeg.add_argument('--skip-root-merge', action='store_true', default=False,
                   help='skip running omicron-root-merge, '
                        'default: %(default)s')
pipeg.add_argument('--skip-ligolw_add', action='store_true', default=False,
                   help='skip running ligolw_add, default: %(default)s')
pipeg.add_argument('--skip-gzip', action='store_true', default=False,
                   help='skip running gzip, default: %(default)s')
pipeg.add_argument('--skip-postprocessing', action='store_true', default=False,
                   help='skip all post-processing, equivalent to '
                        '--skip-root-merge --skip-lioglw_add --skip-gzip, '
                        'default: %(default)s')

args = parser.parse_args()

args.verbose = max(5 - args.verbose, 0)
logger.setLevel(args.verbose * 10)

# validate command line arguments
if args.ifo is None:
    parser.error("Cannot determine IFO prefix from sytem, "
                 "please pass --ifo on the command line")
if args.executable is None:
    parser.error("Cannot find omicron.exe on path, please pass "
                 "--executable on the command line")

# validate processing options
if all((args.skip_root_merge, args.skip_ligolw_add, args.skip_gzip,
        not args.archive)):
    args.skip_postprocessing = True
if args.archive:
    argsd = vars(args)
    for arg in ['skip-root-merge', 'skip-ligolw-add', 'skip-gzip']:
        if argsd[arg.replace('-', '_')]:
            parser.error("Cannot use --%s with --archive" % arg)

ifo = args.ifo
llhoft = data.ligo_low_latency_hoft_type(ifo, use_devshm=args.use_dev_shm)
group = args.group
online = args.gps is None

# format file-tag
filetag = args.file_tag
if filetag:
    filetag = re.sub('[:_\s-]', '_', filetag).rstrip('_').strip('_')
    if const.OMICRON_FILETAG.lower() in filetag.lower():
        afiletag = filetag
    else:
        afiletag = '%s_%s' % (filetag, const.OMICRON_FILETAG.upper())
    filetag = '_%s' % filetag
else:
    filetag = ''
    afiletag = const.OMICRON_FILETAG.upper()

logger.info("--- Welcome to the Omicron processor ---")

tempfiles = []
keepfiles = []

# check rescue against --dagman-option force
if args.rescue and args.dagman_option.count('force') > 1:
    parser.error('--rescue is incompatible with --dagman-option force')
elif args.rescue:
    args.dagman_option.pop(0)
    logger.info("Running in RESCUE mode - the workflow will be re-generated "
                "in memory without any files being written")

# set omicron version for future use
omicronv = utils.get_omicron_version(args.executable)
os.environ.setdefault('OMICRON_VERSION', str(omicronv))
logger.debug('Omicron version: %s' % omicronv)

# XXX reset const variables for Omicron v2r2 XXX
# this can be removed when v2r2 is the stable release
if omicronv >= 'v2r2':
    const.OMICRON_FILETAG = 'OMICRON'


# -- parse configuration file and get parameters ------------------------------

cp = configparser.ConfigParser()
cp.read(args.config_file)

# validate
if not cp.has_section(group):
    raise configparser.NoSectionError(group)

# get params
channels = cp.get(group, 'channels').strip('\n').rstrip('\n').split('\n')
try:  # allow two-column 'channel samplerate' format
    channels, crates = zip(*[c.split(' ', 1) for c in channels])
except ValueError:
    crates = []
else:
    crates = set(crates)
logger.debug("%d channels read" % len(channels))
for i in range(len(channels) -1, -1, -1):  # remove excluded channels
    c = channels[i]
    if c in args.exclude_channel:
        channels.pop(i)
        logger.debug("    removed %r" % c)
logger.debug("%d channels to process" % len(channels))
cp.set(group, 'channels', '\n'.join(channels))
frametype = cp.get(group, 'frametype')
logger.debug("frametype = %s" % frametype)
chunkdur = cp.getint(group, 'chunk-duration')
logger.debug("chunkdur = %s" % chunkdur)
segdur = cp.getint(group, 'segment-duration')
logger.debug("segdur = %s" % segdur)
overlap = cp.getint(group, 'overlap-duration')
logger.debug("overlap = %s" % overlap)
padding = int(overlap / 2)
logger.debug("padding = %s" % padding)
try:
    frange = map(float, cp.get(group, 'frequency-range').split())
except configparser.NoOptionError as e:
    try:
        flow = cp.getfloat(group, 'flow')
        fhigh = cp.getfloat(group, 'flow')
    except configparser.NoOptionError:
        raise e
    frange = (flow, fhigh)
logger.debug('frequencyrange = [%s, %s)' % tuple(frange))
try:
    sampling = cp.getfloat(group, 'sample-frequency')
except configparser.NoOptionError:
    if len(crates) == 1:
        sampling = float(crates[0])
    elif len(crates) > 1:
        raise ValueError("No sample-frequency parameter given, and multiple "
                         "sample frequencies parsed from channels list, "
                         "cannot continue")
    else:
        sampling = None
if sampling:
    logger.debug('samplingfrequency = %s' % sampling)
parameters.validate_parameters(chunkdur, segdur, overlap, frange, sampling)

# get state channel
try:
    statechannel = cp.get(group, 'state-channel')
except configparser.NoOptionError:
    statechannel = None
else:
    try:
        statebits = map(float, cp.get(group, 'state-bits').split(','))
    except configparser.NoOptionError:
        statebits = [0]
    try:
        stateft = cp.get(group, 'state-frametype')
    except configparser.NoOptionError as e:
        e.args = ('%s, this must be specified if state-channel is given'
                  % str(e),)
        raise

# get state flag (if given)
try:
    stateflag = cp.get(group, 'state-flag')
except configparser.NoOptionError:
    stateflag = None
else:
    logger.debug("State flag = %s" % stateflag)
    if online and not statechannel:
        try:
            statechannel, statebits, stateft = segments.STATE_CHANNEL[stateflag]
        except KeyError as e:
            e.args = ('Cannot map state flag %r to channel' % stateflag,)
            raise

if statechannel:
    logger.debug("State channel = %s" % statechannel)
    logger.debug("State bits = %s" % ', '.join(map(str, statebits)))
    logger.debug("State frametype = %s" % stateft)

rundir = utils.get_output_directory(args)
cachedir = os.path.join(rundir, 'cache')

# -- set directories and check for an existing process ------------------------

if not os.path.isdir(rundir):
    os.makedirs(rundir)
logger.info("Using run directory\n%s" % rundir)

condir = os.path.join(rundir, 'condor')
if not os.path.isdir(condir):
    os.makedirs(condir)

# check dagman lock file
running = condor.dag_is_running(os.path.join(condir, 'omicron.dag'), group)
if running and args.reattach:
     logger.info('Detected omicron.dag already running %s, will reattach'
                 % rundir)
elif running:
    raise RuntimeError("Detector omicron.dag in %s is already running"
                       % rundir)
else:
     args.reattach = False

# check dagman rescue files
nrescue = any(map(os.path.isfile, glob(
    os.path.join(condir, 'omicron.dag.rescue[0-9][0-9][0-9]'))))
if args.rescue and nrescue == 0:
    raise RuntimeError("--rescue given but no rescue DAG files found in %s"
                       % condir)
elif not args.rescue and nrescue > 1:
    raise RuntimeError("rescue DAG found in %s, will not continue" % condir)
elif args.rescue and not os.path.isfile(os.path.join(condir, 'omicron.dag')):
    raise RuntimeError("--rescue given by omicron.dag file not found in %s"
                       % condir)

newdag = not args.rescue and not args.reattach


# -- find run segment ---------------------------------------------------------

segfile = os.path.join(rundir, 'segments.txt')
keepfiles.append(segfile)

if newdag and online:
    if frametype == '%s_HOFT_C00' % ifo:
        end = data.get_latest_data_gps(ifo, llhoft)
    else:
        end = data.get_latest_data_gps(ifo, frametype)
    end -= padding
    try:
        start = segments.get_last_run_segment(segfile)[1]
    except IOError:
        if llhoft.endswith('llhoft'):
            logger.debug("No online segment record, starting with "
                         "%s seconds" % chunkdur)
            start = end - chunkdur + padding
        else:
            logger.debug("No online segment record, starting with "
                         "4000 seconds")
            start = end - 4000
    else:
        logger.debug("Online segment record recovered")
elif online:
    start, end = segments.get_last_run_segment(segfile)
else:
    start, end = args.gps

rundir = os.path.abspath(rundir)

duration = end - start
datastart = start - padding
dataend = end + padding
dataduration = dataend - datastart

logger.info("Processing segment determined as")
logger.info("    %d %d" % (datastart, dataend))
logger.info("Duration = %d seconds" % dataduration)

span = (start, end)

# -- double-check frametype for h(t)
# don't use aggregated h(t) if running online

try:
    data.check_data_availability(ifo, '%s_HOFT_C00' % ifo, start, end)
except RuntimeError:
    use_online_hoft = True
    msg = ("Gaps found in %s availability, turning to %s"
           % (frametype, llhoft))
else:
    use_online_hoft = False

if frametype == '%s_HOFT_C00' % ifo and use_online_hoft:
    if online:
        logger.debug(msg)
    else:
        logger.warning(msg)
    frametype = llhoft
if statechannel and use_online_hoft and stateft == '%s_HOFT_C00' % ifo:
    stateft = llhoft

# -- find segments and frame files --------------------------------------------

# validate span is long enough
if dataduration < chunkdur:
    logger.info("Segment is too short (%d < %d), please try again later"
                % (duration, chunkdur - padding * 2))
    clean_exit(0, tempfiles)

# find run segments
if (online and statechannel) or (statechannel and not stateflag):
    logger.info("Finding segments for relevant state...")
    segs = segments.get_state_segments(statechannel, stateft,
                                       datastart, dataend, bits=statebits)
elif stateflag:
    logger.info("Querying segments for relevant state...")
    segs = segments.query_state_segments(stateflag, datastart, dataend)
else:
    segs = segments.get_frame_segments(ifo, frametype, datastart, dataend)

# remove segments that are too short
segs = type(segs)([s for s in segs if abs(s) >= segdur])

if len(segs):
    logger.info("State/frame segments recovered as")
    for seg in segs:
        logger.info("    %d %d" % seg)
    logger.info("Duration = %d seconds" % abs(segs))

# truncate final segment if running online
try:
    lastseg = segs[-1]
except IndexError:
    truncate = False
else:
    truncate = online and newdag and lastseg[1] == dataend

# if segment is shorter than one chunk, leave it until later
if truncate and (
        (not statechannel and abs(lastseg) < chunkdur) or
        (statechannel and abs(lastseg) < (chunkdur + segdur))):
    logger.info("The final segment is too short, but ends at the limit of "
                "available data, presumably this is an active segment. "
                "It will be removed so that it can be "
                "processed properly later")
    segs = type(segs)(segs[:-1])
    dataend = lastseg[0]
# if long enough and no state required, restrict to an integer number of chunks
elif truncate and (not statechannel or abs(lastseg) >= (chunkdur + segdur)):
    logger.info("Truncating to process only complete chunks...")
    t, e = lastseg
    step = chunkdur
    while t + chunkdur <= e:
        t += step
        step = chunkdur - overlap
    segs[-1] = type(segs[-1])(lastseg[0], t)
    dataend = segs[-1][1]
    logger.info("This analysis will now run to %d" % dataend)

dataspan = type(segs)([segments.Segment(datastart, dataend)])

# find the frames
if args.use_dev_shm:
    cache = data.find_frames(ifo, frametype, datastart, dataend,
                             on_gaps='warn', tmpdir=cachedir)
    tempfiles.extend(cache.pfnlist())
else:
    cache = data.find_frames(ifo, frametype, datastart, dataend,
                             on_gaps='warn')
if not online and len(cache) == 0:
    raise RuntimeError("No frames found for %s-%s" % (ifo[0], frametype))
try:
    cachesegs = (segments.cache_segments(cache) & dataspan).coalesce()
except TypeError:  # empty cache
    cachesegs = type(dataspan)()
    alldata = False
else:
    try:
        alldata = cachesegs[-1][1] >= dataspan[-1][1]
    except IndexError:  # no data overlapping span
        alldata = False

# write cache
if not os.path.isdir(cachedir):
    os.makedirs(cachedir)
cachefile = os.path.join(cachedir, 'frames.lcf')
keepfiles.append(cachefile)
if newdag:
    data.write_cache(cache, cachefile)
logger.info("Cache of %d frames written to\n%s" % (len(cache), cachefile))

# restrict analysis to available data
if segs - cachesegs:
    logger.warning("Not all state times are available in frames")
segs = (cachesegs & segs).coalesce()

# if all of the data are available, but no segments, record segments.txt
if newdag and len(segs) == 0 and online and alldata:
    logger.info("No segments found, but up-to-date data are available. "
                "A segments.txt file will be written so we don't have to "
                "search these data again")
    segments.write_segments(cachesegs, segfile)
    logger.info("Segments written to\n%s" % segfile)
    clean_exit(0, tempfiles)
# otherwise not all data are available, so
elif len(segs) == 0 and online:
    logger.info("No segments found, please try again later")
    clean_exit(0, tempfiles)
elif len(segs) == 0:
    raise RuntimeError("No segments found")

# apply minimum duration requirement
segs = type(segs)(s for s in segs if abs(s) >= segdur)
# and calculate trigger output segments
trigsegs = type(segs)(type(s)(*s) for s in segs).contract(padding)

# display segments
logger.info("Final data segments selected as")
for seg in segs:
    logger.info("    %d %d" % seg)
logger.info("Duration = %d seconds" % abs(segs))

span = type(trigsegs)([trigsegs.extent()])

logger.info("This will output triggers for")
for seg in trigsegs:
    logger.info("    %d %d" % seg)
logger.info("Duration = %d seconds" % abs(trigsegs))

# -- make parameters files then generate the DAG ------------------------------

# generate a 'master' parameters.txt file for archival purposes
if newdag:
    tmpparfile = parameters.generate_parameters_files(
        cp, group, cachefile, rundir, channellimit=int(1e8))[0][0]
    parfile = os.path.join(rundir, 'parameters.txt')
    logger.debug("Created master parameters file\n%s" % parfile)
    os.rename(tmpparfile, parfile)
    keepfiles.append(parfile)

# then generate actual parameters files for submission (channel groups)
if args.rescue:
    pardir = gettempdir()
else:
    pardir = rundir
jobfiles = parameters.generate_parameters_files(
    cp, group, cachefile, pardir, channellimit=args.max_channels_per_job)

# create log directory
logdir = os.path.join(rundir, 'logs')
if not os.path.isdir(logdir):
    os.mkdir(logdir)

# create dag
dag = pipeline.CondorDAG(os.path.join(logdir, 'omicron.log'))
dag.set_dag_file(os.path.join(condir, 'omicron'))

# set up condor commands for all jobs
condorcmds = {'accounting_group': args.condor_accounting_group,
              'accounting_group_user': args.condor_accounting_group_user}
for cmd_ in args.condor_command:
    key, value = cmd_.split('=', 1)
    condorcmds[key.rstrip().lower()] = value.strip()

# create omicron job
ojob = condor.OmicronProcessJob(args.universe, args.executable, subdir=condir,
                                logdir=logdir, **condorcmds)
ojob.add_condor_cmd('+OmicronProcess', '"%s"' % group)
nperjob = args.max_chunks_per_job

# create post-processing job
ppjob = condor.OmicronProcessJob(args.universe, utils.which('bash'),
                                 subdir=condir, logdir=logdir,
                                 tag='post-processing', **condorcmds)
ppjob.add_condor_cmd('+OmicronPostProcess', '"%s"' % group)
ppjob.add_short_opt('e', '')
ppnodes = []
rootmerge = utils.which('omicron-root-merge')
ligolw_add = utils.which('ligolw_add')
gzip = utils.which('gzip')

if args.archive:
    archivejob = condor.OmicronProcessJob(
        args.universe, os.path.join(condir, 'archive.sh'),
        subdir=condir, logdir=logdir, tag='archive', **condorcmds)
    archivefiles = {}

for s, e in segs:
    ts = s + padding
    te = e - padding
    td = te - ts

    # work out job segments
    filesegments = segments.omicron_output_segments(
        s, e, chunkdur, segdur, overlap)

    # separate long segments into shorter chunks
    nodesegs = segments.parallel_omicron_segments(
        s, e, chunkdur, overlap, nperjob)

    # build node for each parameter file
    for i, (pf, chanlist) in enumerate(jobfiles):
        nodes = []
        for subseg in nodesegs:
            # process
            if not args.skip_omicron:
                node = pipeline.CondorDAGNode(ojob)
                node.set_category('omicron')
                node.set_retry(str(args.condor_retry))
                node.add_var_arg(str(subseg[0]))
                node.add_var_arg(str(subseg[1]))
                node.add_var_arg(os.path.abspath(pf))
                dag.add_node(node)
                nodes.append(node)

        # post-process
        if not args.skip_postprocessing:
            # build post-processing nodes for each channel
            for c in chanlist:
                script = os.path.join(
                    condir, 'post-process-%s-%d-%d-%d.sh' % (c, s, e, i))
                if not args.rescue:
                    with open(script, 'w') as f:
                        print('#!/bin/bash -e\n', file=f)
                        print("# %s" % c, file=f)  # comment header for sh

                        # work out filenames for coalesced files
                        chandir = os.path.join(rundir, 'triggers', c)
                        cname = re.sub('[:_-]', '_', c).replace('_', '-', 1)
                        target, filename = os.path.split(
                            io.get_archive_filename(
                                c, ts, td, filetag=afiletag, ext='root'))

                        # get list of output files
                        if omicronv >= 'v2r2':
                            roots = ' '.join(
                                os.path.join(chandir, '%s_%s-%d-%d.root' % (
                                    cname, const.OMICRON_FILETAG, fs, fe-fs))
                                for (fs, fe) in filesegments)
                            xmls = roots.replace('.root', '.xml')
                        else:
                            roots = ' '.join(
                                os.path.join(
                                    chandir, '%s_%d_%d.root' % (c, fs, fe-fs))
                                for (fs, fe) in filesegments)
                            xmls = ' '.join(
                                os.path.join(chandir, '%s_%s-%d-%d.xml' % (
                                    cname, const.OMICRON_FILETAG, fs, fe-fs))
                                for (fs, fe) in filesegments)

                        # add omicron-root-merge
                        if args.skip_root_merge or len(filesegments) == 1:
                            root = roots
                        else:
                            root = os.path.join(chandir, filename)
                            print('%s %s %s --strict'
                                  % (rootmerge, roots, root), file=f)

                        # add ligolw_add
                        if args.skip_ligolw_add or len(filesegments) == 1:
                            xml = xmls
                        else:
                            xml = os.path.join(chandir,
                                               filename.replace('root', 'xml'))
                            print('%s %s --output %s'
                                  % (ligolw_add, xmls, xml), file=f)

                        # add gzip
                        if not args.skip_gzip:
                            print('%s --force %s' % (gzip, xml), file=f)
                            xml = '%s.gz' % xml

                        # add archive
                        if args.archive:
                            try:
                                archivefiles[target].extend([xml, root])
                            except KeyError:
                                archivefiles[target] = [xml, root]

                        # add rm jobs (only if files were manipulated)
                        if root != roots:
                            print('rm -f %s' % roots, file=f)
                        if xml != xmls:
                            print('rm -f %s' % xmls, file=f)

                ppnode = pipeline.CondorDAGNode(ppjob)
                ppnode.add_var_arg(script)
                ppnode.set_category('postprocessing')
                if not args.skip_omicron:
                    for node in nodes:
                        ppnode.add_parent(node)
                dag.add_node(ppnode)
                ppnodes.append(ppnode)
                tempfiles.append(script)
                if newdag:
                    os.chmod(script, 0o755)

# set 'strict' option for newer versions of Omicron
if omicronv >= 'v2r2':
    ojob.add_arg('strict')

# do all archiving last, once all post-processing has completed
if args.archive:
    archivenode = pipeline.CondorDAGNode(archivejob)
    xmlcache = Cache()
    rootcache = Cache()
    if newdag:
        # write shell script to seed archive
        with open(archivejob.get_executable(), 'w') as f:
            print('#!/bin/bash -e\n', file=f)
            for gpsdir, filelist in archivefiles.iteritems():
                # write 'mv' op to script
                print("mkdir -p %s" % gpsdir, file=f)
                print("mv %s %s" % (' '.join(filelist), gpsdir), file=f)
                # record archived files in caches
                filenames = [os.path.join(gpsdir, os.path.basename(x)) for
                             x in filelist]
                xmlcache.extend(CacheEntry.from_T050017(x) for x in filenames
                                if x.endswith('xml.gz'))
                rootcache.extend(CacheEntry.from_T050017(x) for x in filenames
                                if x.endswith('root'))
        os.chmod(archivejob.get_executable(), 0o755)
        # write caches to disk
        xmlcachefile = os.path.join(cachedir, 'omicron-xml.lcf')
        data.write_cache(xmlcache, xmlcachefile)
        logger.debug("XML cache written to %s" % xmlcachefile)
        rootcachefile = os.path.join(cachedir, 'omicron-root.lcf')
        data.write_cache(rootcache, rootcachefile)
        logger.debug("ROOT cache written to %s" % rootcachefile)
    # add node to DAG
    for node in ppnodes:
        archivenode.add_parent(node)
    archivenode.set_category('archive')
    dag.add_node(archivenode)
    tempfiles.append(archivejob.get_executable())

dagfile = dag.get_dag_file()
if args.rescue:
    logger.info("In --rescue mode, this DAG has been reproduced in memory "
                "for safety, but will not be written to disk, the file is:")
elif newdag:
    dag.write_sub_files()
    dag.write_dag()
    dag.write_script()
    with open(dagfile, 'a') as f:
        print('DOT %s.dot' % os.path.splitext(dagfile)[0], file=f)
    logger.info("Dag with %d nodes written to" % len(dag.get_nodes()))
    print(os.path.abspath(dagfile))

# write segments now
# this means that online processing will _always_ move on, even if it fails
if newdag:
    segments.write_segments(span, segfile)
    logger.info("Segments written to\n%s" % segfile)

if args.no_submit:
    sys.exit(0)

# -- submit the DAG and babysit -----------------------------------------------

# submit DAG
if args.rescue:
    logger.info("--- Submitting rescue DAG to condor -------")
elif args.reattach:
    logger.info("--- Reattaching to existing DAG -------")
else:
    logger.info("--- Submitting DAG to condor -------")

for i in range(args.submit_rescue_dag + 1):
    if args.reattach:  # find ID of existing DAG
        dagid = condor.find_dagman_id(group, classad="OmicronDAGMan")
        logger.info("Found existing condor ID = %d" % dagid)
    else:  # or submit DAG
        dagmanargs = set()
        dagmanopts = {'-append': '+OmicronDAGMan=\"%s\"' % group}
        for x in args.dagman_option:
            x = '-%s' % x
            try:
                key, val = x.split('=', 1)
            except ValueError:
                dagmanargs.add(x)
            else:
                dagmanopts[key] = val
        dagid = condor.submit_dag(dagfile, *list(dagmanargs), **dagmanopts)
        logger.info("Condor ID = %d" % dagid)
    # wait for DAG to be in running state
    schedd = htcondor.Schedd()
    stat = condor.get_job_status(dagid, schedd)
    while stat != condor.JOB_STATUS_MAP['running']:
        logger.debug('Waiting for DAG to enter R state...')
        dagmansleep = True
        if stat > condor.JOB_STATUS_MAP['running']:
            raise RuntimeError("DAGMan process %s is not in a good state"
                               % dagid)
        sleep(2)
        stat = condor.get_job_status(dagid, schedd)
    else:
        dagmansleep = False
    # DAG was not running, wait for it to initialise
    if not args.reattach or dagmansleep:
        logger.debug("Sleep for 15 seconds while DAGMan starts up")
        sleep(15)
    # find lock file and monitor
    states = ['unready', 'ready', 'idle', 'running', 'held', 'failed', 'done']
    colors = ['white', 'magenta', 'white', 'blue', 'yellow', 'red', 'green']
    old = dict((k, -1) for k in states)
    if not args.reattach:
        logger.info("Monitoring DAG via ID...")
        logger.debug("Dag Status (%d nodes total):" % (len(dag.get_nodes())))
    logger.debug('-' * 68)
    logger.debug('{0} |   {1} |    {2} | {3} |    {4} |  {5} |'
                 '    {6}'.format(
             *[log.color_text(s, c) for s, c in zip(states, colors)]))
    logger.debug('-' * 68)
    for job in condor.iterate_dag_status(dagid):
        for state in states:
            if job[state] != old[state]:
                logger.debug(' | '.join(['%7s' % job[s] for s in states]))
                break
        old = job
    logger.debug('-' * 68)
    # log exitcode
    if job['exitcode']:
        logger.critical("DAG has exited with status %d" % job['exitcode'])
    else:
        logger.info("DAG has exited with status %d" % job['exitcode'])
        break
    # handle failure
    if i == args.submit_rescue_dag:
        raise RuntimeError("DAG has failed to complete %d times"
                           % (args.submit_rescue_dag + 1))
    else:
        sleep(2)
        rescue = condor.find_rescue_dag(dagfile)
        logger.warning("Rescue DAG %s was generated" % rescue)

# mark output and error files of condor nodes that passed to be deleted
try:
    for node, files in condor.get_out_err_files(dagid, exitcode=0).items():
        tempfiles.extend(files)
except RuntimeError:
    pass

# archive files
stub = '%d-%d' % (start, end)
for f in ['%s.dagman.out' % dagfile] + keepfiles:
    base, ext = os.path.splitext(os.path.basename(f))
    archive = os.path.join(logdir, '%s-%s%s' % (base, stub, ext))
    if 'dagman.out' in f:
        os.rename(f, archive)
    else:
        shutil.copyfile(f, archive)
    logger.debug("Archived file\n%s --> %s" % (f, archive))

# clean up temporary files
tempfiles.extend(glob(os.path.join(rundir, 'triggers', 'ffconvert.*.ffl')))
clean_tempfiles(tempfiles)

# and exit
logger.info("---- Processing complete -----------")
